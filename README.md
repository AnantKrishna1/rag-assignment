# RAG-based EdTech MVP — Economics Chapter

**Purpose:**  
This repository contains a minimal, reproducible MVP that implements a Retrieval-Augmented Generation (RAG) pipeline for an economics book chapter. It extracts clean searchable knowledge from a PDF chapter, creates chunk-level embeddings and a FAISS vector DB, builds a topic knowledge graph, processes YouTube video transcripts into lesson pages (overview → time-stamped highlights → key terms → 5 MCQs + 1 essay question), and provides a Streamlit demo for RAG-based QA and student answer assessment.


## Quick checklist — assignment coverage

The code in this repository provides working code to perform the following required tasks:

- ✅ Extract clean searchable knowledge from the provided chapter PDF (page-level extraction + chunking).  
- ✅ Attach metadata fields for each chunk: **subject**, **topic** (heuristic), **subtopic** (placeholder), **difficulty** (default/manual).  
- ✅ Store clean text chunks in an object store (`data/*.jsonl`).  
- ✅ Embed the chunks using `sentence-transformers` and store embeddings in **FAISS** (vector DB).  
- ✅ Build a simple **knowledge graph** (co-occurrence of keywords) and save as an image.  
- ✅ From YouTube videos: fetch transcripts, create lesson pages with overview, time-stamped highlights, key terms using YAKE, and generate **5 MCQs** + **1 essay question** per video (generated by Flan-T5 small).  
- ✅ Provide a **Streamlit** MVP that supports:
  - RAG search + answer generation (retrieval + Flan-T5 generation),
  - Lesson pages display (from video transcripts),
  - Student answer assessment (embedding similarity-based scoring).
- ✅ Scripts and step-by-step instructions to reproduce locally or in Google Colab.

**Limitations / notes:**  
- MCQ/Essay generation uses the free model `google/flan-t5-small` (CPU-friendly). It produces reasonable outputs for an MVP but may be less polished than commercial LLMs.  
- Video transcript extraction uses `youtube-transcript-api` where transcripts are available; if unavailable, use `yt-dlp` + `whisper` workflow (instructions included in repo).  
- Topic/subtopic/difficulty metadata are set via heuristics by default; manual refinement improves production quality.

---

## Repo structure

rag-assignment/
├─ data/
│ ├─ chapter.pdf # input (you must download)
│ ├─ chunks.jsonl # page-level extracted text
│ ├─ emb_chunks.jsonl # chunked text with metadata
│ ├─ emb_metadata.jsonl # mapping from index -> chunk metadata
│ ├─ embeddings.npy # optional saved embeddings
│ ├─ faiss_index.index # FAISS index file
│ └─ video_transcripts.jsonl
├─ src/
│ ├─ 0_setup_env.sh
│ ├─ ingest_pdf.py
│ ├─ chunker.py
│ ├─ embed_store.py
│ ├─ build_graph.py
│ ├─ process_videos.py
│ ├─ generate_questions.py
│ ├─ assess_answer.py
│ └─ app_streamlit.py
├─ pages/ # generated lesson pages (optional)
├─ requirements.txt
├─ README.md #



---

## Setup (local) — Windows, macOS, Linux

**Recommended:** Use WSL on Windows or run in Google Colab if you want no local setup.

### 1. Create virtual environment & install
```bash
# from repo root
python -m venv venv
# activate
# Windows (PowerShell)
.\venv\Scripts\Activate.ps1
# or Windows (cmd)
.\venv\Scripts\activate
# macOS / Linux
source venv/bin/activate

pip install --upgrade pip
pip install -r requirements.txt
